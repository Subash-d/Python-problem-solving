{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68ea67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kissing my gf feels like, I've got to get over it.\n",
      "\n",
      "I've had a few fights with her, and she's definitely done some good in the past, but I'm really glad she's not getting hurt.\n",
      "\n",
      "I love her.\n",
      "\n",
      "But, I've got to say, I'm disappointed in her.\n",
      "\n",
      "To me, she seems like a sweet person.\n",
      "\n",
      "She has a nice personality.\n",
      "\n",
      "And, I'm also disappointed in her.\n",
      "\n",
      "I told you before, I'm not in love with her.\n",
      "\n",
      "And, I'm so happy about her.\n",
      "\n",
      "I just don't like her.\n",
      "\n",
      "But, I feel like, I want to help her.\n",
      "\n",
      "I can't help but feel like, I'm not really that good with her.\n",
      "\n",
      "And, I'm not really that good with her.\n",
      "\n",
      "I'm hoping she's okay.\n",
      "\n",
      "A moment or two after that, I take this shot, and she's not happy.\n",
      "\n",
      "We both come back to the gym and we have some fun.\n",
      "\n",
      "That's how we get to the gym.\n",
      "\n",
      "We go to the gym and I'm really busy.\n",
      "\n",
      "I want to make sure she's OK.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "result = generator(\"Kissing my gf feels like,\", max_length=400, num_return_sequences=1)\n",
    "\n",
    "print(result[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e00b5dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I love learning Machine Learning with transformers!\n",
      "Label: POSITIVE, Score: 0.9994\n",
      "--------------------------------------------------\n",
      "Text: This project is really hard and frustrating.\n",
      "Label: NEGATIVE, Score: 0.9995\n",
      "--------------------------------------------------\n",
      "Text: I do not love my dog but hate cats and other animals\n",
      "Label: NEGATIVE, Score: 0.9900\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained DistilBERT sentiment model\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "# Example sentences\n",
    "texts = [\n",
    "    \"I love learning Machine Learning with transformers!\",\n",
    "    \"This project is really hard and frustrating.\",\n",
    "    \"I do not love my dog but hate cats and other animals\",\n",
    "]\n",
    "\n",
    "# Predict sentiments\n",
    "results = classifier(texts)\n",
    "\n",
    "# Print results\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Label: {result['label']}, Score: {result['score']:.4f}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d42c542",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
